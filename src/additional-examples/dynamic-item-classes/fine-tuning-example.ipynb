{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6785f47a-5670-45a9-80df-a4d6f47b1181",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To complete the following guide you will need to install the following packages:\n",
    "- fireworks-ai\n",
    "- pandas\n",
    "- requests\n",
    "\n",
    "You will also need:\n",
    "\n",
    "- Fireworks account (https://fireworks.ai/)\n",
    "- Fireworks API key\n",
    "- The firectl command-line interface (https://docs.fireworks.ai/tools-sdks/firectl/firectl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e869493a-09c8-4036-8573-12a1d33e8723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/scottkramer/.pyenv/versions/3.8.16/envs/fine-tuning-workshop/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas requests fireworks-ai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56a030b-9e82-43cc-8cde-ab20da4280a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from fireworks.client import Fireworks\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09b2526b-5718-4c9e-9e56-69314314d76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/09/12 12:51:31 There are updates available.\n",
      "Current version: 1.2.0\n",
      "Latest version: 1.3.0\n",
      "\n",
      "To upgrade to the latest version, run\n",
      "  $ sudo firectl upgrade\n",
      "\n",
      "Signed in as: sdkramer10@gmail.com\n",
      "Account ID: sdkramer10-5e98cb\n"
     ]
    }
   ],
   "source": [
    "# Sign-in to your Fireworks account\n",
    "!firectl signin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3a5636ee-8032-4f24-b69a-c90414078d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have the FIREWORKS_API_KEY environment variable set to your account's key!\n",
    "# os.environ['FIREWORKS_API_KEY'] = 'XXX'\n",
    "\n",
    "client = Fireworks()\n",
    "\n",
    "# Replace the line below with your Fireworks account id\n",
    "account_id = 'XXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5393f-9f6e-431d-b2ab-86fd9082e663",
   "metadata": {},
   "source": [
    "## Problem Definition: Dynamic Insurance Support Ticket Classifier\n",
    "\n",
    "*Note: The problem definition, data, and labels used in this example were synthetically generated by Claude 3 Opus*\n",
    "\n",
    "In the insurance industry, customer support plays a crucial role in ensuring client satisfaction and retention. Insurance companies receive a high volume of support tickets daily, covering a wide range of topics such as billing, policy administration, claims assistance, and more. Manually categorizing these tickets can be time-consuming and inefficient, leading to longer response times and potentially impacting customer experience.\n",
    "\n",
    "### Task\n",
    "In the week 2 folder, we perform static support ticket classification, where the list of possible categories are injectd into the prompt.\n",
    "In this example, we do not include the categories in the prompt, and instead make determining the categories a generative task.\n",
    "\n",
    "There are three primary differences between this notebook and the week 2 notebook that contains static labels:\n",
    "- Remove 'General Inquiries' as a category from the training data. Otherwise, the model will learn to place all tickets that do not fall into the other categories as 'General Inquiries'\n",
    "- Remove the list of possible categories from the prompt\n",
    "- Increase the aggressiveness of training (rank, learning rate, and number of epochs). This ensures the model is biased towards responding with a category that exists in the training data, and only responds with a different category when necessary. Lowering these parameters will cause the model to more aggressively respond with categories that were not in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da13a3-2659-4711-ab5e-2042895f2d45",
   "metadata": {},
   "source": [
    "#### Labeled Data\n",
    "\n",
    "The data can be found in the `data` folder.\n",
    "\n",
    "We will use the following datasets:\n",
    "- `./data/train.tsv`\n",
    "- `./data/test.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d53b80e9-1bf8-4da1-832e-6c44b781112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "test_examples = pd.read_csv('data/test.tsv', sep='\\t')\n",
    "\n",
    "# Don't include General Inquiries in the training data, otherwise the fine-tuned model will just label all new categories as General Inquiries\n",
    "training_examples = training_examples[training_examples['label'] != 'General Inquiries']\n",
    "test_examples = test_examples[test_examples['label'] != 'General Inquiries']\n",
    "\n",
    "training_tickets = training_examples['text'].tolist()\n",
    "training_labels = training_examples['label'].tolist()\n",
    "\n",
    "test_tickets = test_examples['text'].tolist()\n",
    "test_labels = test_examples['label'].tolist()\n",
    "\n",
    "training_categories = set(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6466bc92-6b43-46a3-8454-ae42eabd3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got my auto policy renewal bill and the cost seems to be more than what I usually pay. Could you explain the reason for the increase?\n",
      "Billing Inquiries\n"
     ]
    }
   ],
   "source": [
    "print(training_tickets[0])\n",
    "print(training_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810815db-a6b2-4d1c-bea8-f4975cbcc3b9",
   "metadata": {},
   "source": [
    "### Dataset Curation\n",
    "\n",
    "We first must transform our dataset into the format expected by Fireworks, and then upload the dataset. The dataset must conform to the schema expected by the Chat Completions API.\n",
    "\n",
    "See https://docs.fireworks.ai/fine-tuning/fine-tuning-models#conversation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0f1f8c6a-90e7-4d32-b9b6-9de0a52c51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(ticket):\n",
    "    return f\"\"\"Classify the customer support ticket.\n",
    "\n",
    "Here is the customer support ticket:    \n",
    "<ticket>{ticket}</ticket>\n",
    "\n",
    "Respond using this format:\n",
    "<category>The category label you chose goes here</category>\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1f2e886f-494d-4f51-8e00-72c2a18e2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the training examples to the format expected by Fireworks.\n",
    "def training_examples_to_json(examples):\n",
    "    json_objs = list()\n",
    "    for idx, example in examples.iterrows():  \n",
    "        user_msg = create_prompt(example['text'])\n",
    "        asst_msg = f\"<category>{example['label']}</category>\"\n",
    "\n",
    "        if example['label'] == \"General Inquiries\":\n",
    "            continue\n",
    "            \n",
    "        msg = {\"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_msg}, \n",
    "            {\"role\": \"assistant\", \"content\": asst_msg}\n",
    "        ]}\n",
    "        json_objs.append(msg)\n",
    "    \n",
    "    return json_objs\n",
    "\n",
    "training_json = training_examples_to_json(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68de340d-f246-4243-a205-5a4ebf2b7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the data to a file so that it can be uploaded to Fireworks\n",
    "dataset_file_name = 'ticket-classification_training_data.jsonl'\n",
    "dataset_id = 'dynamic-ticket-classification-v1'\n",
    "\n",
    "with open(dataset_file_name, 'w') as f:\n",
    "    for obj in training_json:\n",
    "        json.dump(obj, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6a68299-9751-4263-ae87-1a9a531caf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow instructions here to first install the firectil CLI - https://readme.fireworks.ai/docs/fine-tuning-models#installing-firectl\n",
    "# Then run this command to upload the file to Fireworks\n",
    "!firectl create dataset {dataset_id} {dataset_file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fb601-ff13-40fb-967a-b8ebc098fd48",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "\n",
    "We will now fine-tune models using the Fireworks API. Fireworks implements the QLoRA algorithm through a simple interface. Training parameters can be set via the --settings-file argument. In this exercise, we the increase the rank, learning rate, and epochs to make the fine-tuning more aggressively learn the categories we trained on. Otherwise, the fine-tuned model will create new categories too often.\n",
    "\n",
    "See https://docs.fireworks.ai/fine-tuning/fine-tuning-models#starting-your-tuning-job for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee8dd75b-d1d4-4e9c-be55-e7c7777cbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a training job with the default hyperparameters\n",
    "!firectl create fine-tuning-job --settings-file ticket_classification.yaml --display-name dynamic-ticket-classification --dataset {dataset_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8565ac9-eb20-4070-8c7c-7796d199f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT THESE IDS WILL CHANGE WHEN YOU RUN THE FINE-TUNING JOB ON YOUR ACCOUNT!!!\n",
    "# The model id is printed in the stdout of the cell above as Name: accounts/{account_id}/fineTuningJobs/{model_id}\n",
    "model_id = '0933f6f375534b62996ce23f4a8dfb09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "498a82de-3e66-47ec-bab4-b951ef86c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the State of the two fine-tuning jobs are listed as COMPLETED (~10-20 minutes)\n",
    "!firectl get fine-tuning-job {model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df2a33-7d60-4ee7-8b2c-7c1d08c90ce9",
   "metadata": {},
   "source": [
    "### Evluate Results\n",
    "\n",
    "We will now deploy our models and evaluate the results. In addition to evaluating the fine-tuned model accuracy, we'll also test a new ticket that does not fall into any of the tickets that we fine-tuned on. We'll see that our model correctly creates a new category for this ticket called \"App Issues\".\n",
    "\n",
    "See https://docs.fireworks.ai/fine-tuning/fine-tuning-models#deploying-the-model-for-inference for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c6d45aab-a44f-4442-8e84-e14751b688d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to a Fireworks serverless endpoint\n",
    "!firectl deploy {model_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f081c2cc-d5a5-4763-8902-5833522c7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the the Deploymed Model Refs lists the state of the models as \"DEPLOYED\" (~5-20 minutes).\n",
    "!firectl get model {model_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cbba9937-f451-4677-98aa-9f489f0927d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses an LLM to predicted class labels for a list of support tickets\n",
    "def classify_tickets(tickets, model):\n",
    "    responses = list()\n",
    "\n",
    "    for ticket in tickets:\n",
    "        user_prompt = create_prompt(ticket)\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                { \"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            # setting temperature to 0 for this use case, so that responses are as deterministic as possible\n",
    "            temperature=0, \n",
    "            stop=[\"</category>\"],\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "        response = response.choices[0].message.content.split(\"<category>\")[-1].strip()\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses\n",
    "\n",
    "\n",
    "# Calculates the percent of predictions we classified correctly\n",
    "def evaluate_accuracy(predicted, actual):\n",
    "    num_correct = sum([predicted[i] == actual[i] for i in range(len(actual))])\n",
    "    return round(100 * num_correct / len(actual), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "256d7c65-4050-43e0-881d-58a1ad398de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 76.47%\n",
      "Test Set Accuracy: 77.94%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the fine-tuned model performs\n",
    "model_id = f'accounts/{account_id}/models/{model_id}'\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d517eeb4-1073-4c9f-b9aa-f9f521b2c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ticket Category\n",
      "App Errors\n",
      "\n",
      "Categories Trained On:\n",
      "Coverage Explanations\n",
      "Quotes and Proposals\n",
      "Policy Administration\n",
      "Claims Assistance\n",
      "Claims Disputes\n",
      "Billing Inquiries\n",
      "Billing Disputes\n",
      "Policy Comparisons\n",
      "General Inquiries\n",
      "Account Management\n"
     ]
    }
   ],
   "source": [
    "# Test a new ticket that does not belong to any of the categories we trained on, and observe how our model labels this new ticket.\n",
    "app_errors_ticket_description = \"I keep getting an error that says '404 not found' when opening the mobile app.\"\n",
    "\n",
    "app_errors_classification = classify_tickets(\n",
    "    tickets=[tech_support_ticket_description],\n",
    "    model=model_id\n",
    ")[0]\n",
    "\n",
    "print('New Ticket Category')\n",
    "print(app_errors_classification)\n",
    "\n",
    "print('\\nCategories Trained On:')\n",
    "print('\\n'.join(training_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "86c759ab-f84e-44bb-b621-86550519c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undeploy the first model (does not cost anything extra, but Fireworks may limit your number of deployed models).\n",
    "!firectl undeploy {model_id}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
